{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6c878d-8813-436b-8d0d-753eabfc6d0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training Script for Probe Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b7e549-a812-4f4b-92ff-f9a23d38226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0908 16:18:10.913000 14115 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "from data_management import fetch_dataset_from_hf\n",
    "from training import probing_trainer\n",
    "from model import ClassifierWithTTA\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a84ae7-f58e-4c40-a544-48245accec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = fetch_dataset_from_hf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba28a89-5a2f-43a3-b97b-2419070eb033",
   "metadata": {},
   "source": [
    "## Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d609d6-9e2e-4a86-b7eb-421c81009d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierWithTTA(classifier_hidden_layers=0)\n",
    "model.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7b55c-ba3e-4735-8388-7beeecb8a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = probing_trainer(model, train, val, num_train_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ddfcf-0065-4576-884c-1ef0311ec171",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ba9fb-8901-4ddf-a21c-cb3581a4367b",
   "metadata": {},
   "source": [
    "## ViT probe - 2 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a7861-d96d-4107-ac49-af74934e6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierWithTTA(classifier_hidden_layers=2, classifier_kwargs={\n",
    "                              'hidden_dropout_prob': 0.3,\n",
    "                              'attention_probs_dropout_prob': 0.3\n",
    "                            }\n",
    "                         )\n",
    "model.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa0887-28e3-4fba-86d8-1c1f89e1be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = probing_trainer(model, train, val, num_train_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b704d58-7e66-4ee7-84f5-5c2aee51768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33ca81-637e-4ff8-8021-20a506e345a9",
   "metadata": {},
   "source": [
    "## ViT probe - 4 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fa0b1-52bc-449a-811c-30095353171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierWithTTA(classifier_hidden_layers=4, classifier_kwargs={\n",
    "                              'hidden_dropout_prob': 0.3,\n",
    "                              'attention_probs_dropout_prob': 0.3\n",
    "                            }\n",
    "                         )\n",
    "model.freeze_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b8d1f-92d0-4b63-b1f3-a9fc57085538",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = probing_trainer(model, train, val, num_train_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53470c5-dd98-4907-98fb-e904c4a87c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651406f1-b23f-4130-8d2c-11f7ac7c4cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aef021e6-7f4f-4b53-b8c9-05ba52992c46",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22738c03-c964-4e98-a87e-3a5778021e66",
   "metadata": {},
   "source": [
    "# Train script for full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b9bc576-8ff8-4e91-b265-043bab3703cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 13:10:57.999000 1153 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "from data_management import fetch_dataset_from_hf\n",
    "from training import full_trainer_classification\n",
    "from model import ClassifierWithTTA\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1037ffe-bb29-4181-abf0-8b4dd365e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = fetch_dataset_from_hf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6e734e-1cdd-488e-90ea-04c8da8fb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ClassifierWithTTA\n",
    "from safetensors import safe_open\n",
    "\n",
    "def load_model_with_dropout(classifier_hidden_layers,\n",
    "               embedding_kwargs={\n",
    "                              'hidden_dropout_prob': 0.3,\n",
    "                              'attention_probs_dropout_prob': 0.3\n",
    "                            },\n",
    "               classifier_kwargs={\n",
    "                              'hidden_dropout_prob': 0.3,\n",
    "                              'attention_probs_dropout_prob': 0.3\n",
    "                            }):\n",
    "    folder = {\n",
    "                0: \"linear_probe\",\n",
    "                2: \"vit2_probe\",\n",
    "                4: \"vit4_probe\"\n",
    "             }.get(classifier_hidden_layers)\n",
    "    \n",
    "    tensors = {}\n",
    "    with safe_open(f\"{folder}/checkpoint-62500/model.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "\n",
    "    model = ClassifierWithTTA(classifier_hidden_layers=classifier_hidden_layers,\n",
    "                              classifier_kwargs=classifier_kwargs,\n",
    "                              embedding_kwargs=embedding_kwargs\n",
    "                             )\n",
    "    model.load_state_dict(tensors)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72895ace-b61c-43ac-a538-a7aab1a644b5",
   "metadata": {},
   "source": [
    "## Linear decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302281e6-62fa-4c17-b8ff-994232589de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = load_model_with_dropout(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf7a2ba-b662-4d77-b7f0-11d5e83870cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = full_trainer_classification(linear_model, train, val,\n",
    "                                      num_train_epochs=3,\n",
    "                                      output_dir='linear_full',\n",
    "                                      run_name='linear_full'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eff1c0-180b-473f-9a90-03e067d8e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlrast\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/luke/Documents/modelSetup/reproductions/MAE_TTA/wandb/run-20250913_131209-daotyk2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lrast/huggingface/runs/daotyk2u' target=\"_blank\">linear_full</a></strong> to <a href='https://wandb.ai/lrast/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lrast/huggingface' target=\"_blank\">https://wandb.ai/lrast/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lrast/huggingface/runs/daotyk2u' target=\"_blank\">https://wandb.ai/lrast/huggingface/runs/daotyk2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/.local/defaultPythonEnv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "W0913 13:12:17.547000 1431 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.550000 1429 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.550000 1426 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.551000 1430 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.551000 1433 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.552000 1428 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.562000 1427 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "W0913 13:12:17.586000 1432 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='822' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  822/37500 02:33 < 1:54:14, 5.35 it/s, Epoch 0.07/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817839a-79c6-42ac-b508-c2fa365df95c",
   "metadata": {},
   "source": [
    "## ViT2 decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563ae96-b46a-4d4b-8fcb-cccc4a2f7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit2_model = load_model_with_dropout(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbaa73a-cca0-41ad-b42c-a25ea395dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = full_trainer_classification(vit2_model, train, val,\n",
    "                                      num_train_epochs=3,\n",
    "                                      output_dir='vit2_full',\n",
    "                                      run_name='vit2_full'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd3403-760f-4207-b3ae-b17730767c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e15da1-a2d3-4da0-a69d-dae982a550ac",
   "metadata": {},
   "source": [
    "## ViT4 decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a6b27-34cd-4279-aa39-287533687c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit4_model = load_model_with_dropout(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f814cd-7a1d-463e-87d7-eab9c743b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = full_trainer_classification(vit4_model, train, val,\n",
    "                                      num_train_epochs=3,\n",
    "                                      output_dir='vit4_full',\n",
    "                                      run_name='vit4_full'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86af35-3782-4455-ae4f-b7e88c5495ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344d6fd-50bf-4096-a145-1aed63a8db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
