{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:07.282819Z","iopub.execute_input":"2025-06-10T13:58:07.283038Z","iopub.status.idle":"2025-06-10T13:58:09.057232Z","shell.execute_reply.started":"2025-06-10T13:58:07.283011Z","shell.execute_reply":"2025-06-10T13:58:09.056562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nmy_secret = user_secrets.get_secret(\"wandb key\")\n\nimport wandb\nwandb.login(key=my_secret)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:09.057894Z","iopub.execute_input":"2025-06-10T13:58:09.058176Z","iopub.status.idle":"2025-06-10T13:58:18.480249Z","shell.execute_reply.started":"2025-06-10T13:58:09.058159Z","shell.execute_reply":"2025-06-10T13:58:18.479430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport pytorch_lightning as pl\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom torchvision.datasets import CIFAR10\nfrom torchvision import transforms\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ncifar_train = CIFAR10(root='/kaggle/temp/', train=True, transform=transform, download=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:18.481993Z","iopub.execute_input":"2025-06-10T13:58:18.482592Z","iopub.status.idle":"2025-06-10T13:58:42.039569Z","shell.execute_reply.started":"2025-06-10T13:58:18.482572Z","shell.execute_reply":"2025-06-10T13:58:42.038961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# datasets contents\nimport numpy as np\nimport torch\n\nfrom torch.utils.data import TensorDataset\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms.functional import rotate\n\n\ndef rotated_dataset(images, method='all', return_dataset=True, tensor_embedding=False):\n    \"\"\" make a dataset of rotated images \"\"\"\n    all_images = []\n    all_angles = []\n\n    angles = [0, 90, -90, 180]\n    for image in images:\n        if method == 'all':\n            rotations = angles\n        else:\n            rotations = [np.random.choice(angles)]\n\n        for angle in rotations:\n            all_images.append(rotate(image, int(angle)))\n            all_angles.append(angle)\n\n    all_images = torch.stack(all_images)\n    all_angles = torch.as_tensor(all_angles)\n\n    if tensor_embedding:\n        # embed as tensors\n        angles_radians = (2*np.pi / 360) * all_angles\n        all_angles = torch.stack([torch.cos(angles_radians),\n                                 torch.sin(angles_radians)], dim=-1)\n    else:\n        # embed angles as class labels\n        indices = {angle: i for i, angle in enumerate(angles)}\n        all_angles = torch.as_tensor(list(map(lambda x: indices[x.item()], all_angles)))\n\n    if not return_dataset:\n        return all_images, all_angles\n\n    return TensorDataset(all_images, all_angles)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:42.042925Z","iopub.execute_input":"2025-06-10T13:58:42.043125Z","iopub.status.idle":"2025-06-10T13:58:42.050305Z","shell.execute_reply.started":"2025-06-10T13:58:42.043109Z","shell.execute_reply":"2025-06-10T13:58:42.049491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TTT Model\nimport torch\nimport pytorch_lightning as pl\n\nfrom torch import nn\nfrom collections import OrderedDict\nfrom torchvision.models import resnet50, ResNet50_Weights\n\n\nclass TTTModel(pl.LightningModule):\n    \"\"\" Version of a backbone model that implements Test Time Training\n        on a specific \n    \"\"\"\n    def __init__(self, branch_layer='layer2', train_mode='base_only',\n                 target_embedding='angular', n_classes=10\n                 ):\n        super(TTTModel, self).__init__()\n        self.save_hyperparameters()\n\n        self.primary = resnet50(weights=ResNet50_Weights.DEFAULT)\n        self.secondary = resnet50(weights=ResNet50_Weights.DEFAULT)\n\n        # setup angle decoding model by mixing the two resnets together\n        module_names = list(self.primary._modules.keys())\n        branch_ind = module_names.index(branch_layer)\n\n        TTTBranch = OrderedDict([\n                            (key, self.primary._modules[key]) if i <= branch_ind\n                            else (key, self.secondary._modules[key])\n                            for i, key in enumerate(module_names)\n                            ])\n        # slight quirk of the Resnet implementation: it doesn't work as a\n        # simple series of modules. We need to flatten\n        TTTBranch['flatten'] = nn.Flatten()\n        TTTBranch.move_to_end('fc')\n        self.TTTBranch = nn.Sequential(TTTBranch)\n\n        # decoders \n        self.class_decoder = nn.Linear(1000, n_classes)\n\n        angle_dims = (2 if target_embedding == 'angular' else 4)\n        self.angle_decoder = nn.Linear(1000, angle_dims)\n\n        # losses\n        self.classification_loss = nn.CrossEntropyLoss()\n\n        if target_embedding == 'angular':\n            self.angle_loss = lambda x, y: nn.functional.cosine_similarity(x, y).mean()\n        else:\n            self.angle_loss = nn.CrossEntropyLoss()\n\n        # mode for training\n        self.train_mode = train_mode\n\n    def forward(self, x):\n        return self.class_decoder(self.primary(x))\n\n    def forward_branch(self, x):\n        return self.angle_decoder(self.TTTBranch(x))\n\n    # train, val, test logic\n    def training_step(self, batch, batchind=None):\n        x, y = batch\n        if self.train_mode == 'test_time':\n            loss = self.angle_loss(self.forward_branch(x), y)\n\n        if self.train_mode == 'base_only':\n            loss = self.classification_loss(self.forward(x), y)\n\n        if self.train_mode == 'joint':\n            classification_loss = self.classification_loss(self.forward(x), y)\n\n            rotated, angle = rotated_dataset(x,  method='sample', return_dataset=False,\n                                             tensor_embedding=(\n                                                self.hparams.target_embedding == 'angular'\n                                                )\n                                             )\n            angle_loss = self.angle_loss(self.forward_branch(rotated), angle.to(self.device))\n\n            loss = classification_loss + angle_loss\n\n        self.log('Train loss', loss)\n        return loss\n\n    def validation_step(self, batch, batch_ind=None):\n        x, y = batch\n        outputs = self.forward(x)\n        predictions = torch.argmax(outputs, axis=1)\n        accuracy = (predictions == y).to(torch.float32).mean()\n        \n        loss = self.classification_loss(outputs, y)\n        self.log('Val loss', loss)\n        self.log('Val accuracy', accuracy)\n\n    def test_step(self, batch, batch_ind=None):\n        x, y = batch\n        outputs = self.forward(x)\n        predictions = torch.argmax(outputs, axis=1)\n        accuracy = (predictions == y).to(torch.float32).mean()\n\n        self.log('test accuracy', accuracy)\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n\n    # utilities for freezing different parts of the model.\n    def freeze_primary(self):\n        for parameter in self.primary.parameters():\n            parameter.requires_grad = False\n\n    def unfreeze_primary(self):\n        for parameter in self.primary.parameters():\n            parameter.requires_grad = True\n\n    def freeze_secondary(self):\n        for parameter in self.secondary.parameters():\n            parameter.requires_grad = False\n    \n    def unfreeze_sceondary(self):\n        for parameter in self.secondary.parameters():\n            parameter.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:42.051066Z","iopub.execute_input":"2025-06-10T13:58:42.051343Z","iopub.status.idle":"2025-06-10T13:58:42.074814Z","shell.execute_reply.started":"2025-06-10T13:58:42.051314Z","shell.execute_reply":"2025-06-10T13:58:42.074044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_set, val_set = torch.utils.data.random_split(cifar_train, (0.95, 0.05))\n\ntrain_dl = torch.utils.data.DataLoader(train_set, batch_size=32,\n                                          shuffle=True, num_workers=4, persistent_workers=True)\nval_dl = torch.utils.data.DataLoader(train_set, batch_size=32, num_workers=4, persistent_workers=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:42.075466Z","iopub.execute_input":"2025-06-10T13:58:42.075730Z","iopub.status.idle":"2025-06-10T13:58:42.097626Z","shell.execute_reply.started":"2025-06-10T13:58:42.075708Z","shell.execute_reply":"2025-06-10T13:58:42.097038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n\nimport wandb\n\ndef train_model(model, dir_name):\n    wandb.init(reinit=True, project='ttt')\n    logger = WandbLogger(project='ttt')\n    early_stopping = EarlyStopping(monitor=\"Val accuracy\", mode=\"max\", patience=5)\n    checkpoint_callback = ModelCheckpoint(dirpath=f'/kaggle/working/{dir_name}', save_top_k=1,\n                                          monitor=\"Val accuracy\", mode='max')\n\n    trainer = pl.Trainer(logger=logger, callbacks=[checkpoint_callback, early_stopping])\n    trainer.fit(model, train_dl, val_dl)\n    wandb.finish()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:42.098265Z","iopub.execute_input":"2025-06-10T13:58:42.098806Z","iopub.status.idle":"2025-06-10T13:58:42.103715Z","shell.execute_reply.started":"2025-06-10T13:58:42.098783Z","shell.execute_reply":"2025-06-10T13:58:42.103146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(1,5):\n    model = TTTModel(branch_layer=f'layer{i}', train_mode='joint')\n    train_model(model,f'layer{i}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T13:58:42.105767Z","iopub.execute_input":"2025-06-10T13:58:42.105961Z","iopub.status.idle":"2025-06-10T14:08:40.288383Z","shell.execute_reply.started":"2025-06-10T13:58:42.105946Z","shell.execute_reply":"2025-06-10T14:08:40.287785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}